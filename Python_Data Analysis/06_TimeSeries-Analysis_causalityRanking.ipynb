{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42174438",
   "metadata": {},
   "source": [
    "# TimeSeries Analysis, Causality Ranking\n",
    "We'll use some ideas from EDA_02 and EDA_03 notebooks, which simulated a slider effect.\n",
    "\n",
    "Our goal is to compare the average R² between the RECENT CHANGE in predictor variable (as a %) with the CHANGE in the target variable (as a %), given various deltas.\n",
    "We'll mark any correlation with p-value of less than 5% as being 0.\n",
    "\n",
    "This time, we'll use all the new data we've gathered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06f1a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4a1b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = pd.read_csv(\"../Data_Sets/processed/completeData_1995-2022.csv\")\n",
    "\n",
    "# Renaming Economic freedom columns\n",
    "df_master = df_master.rename(columns={\n",
    "    'Property Rights':'EF_Property Rights',\n",
    "    'Government Integrity':'EF_Government Integrity',\n",
    "    'Judicial Effectiveness':'EF_Judicial Effectiveness',\n",
    "    'Government Spending':'EF_Government Spending',\n",
    "    'Tax Burden':'EF_Tax Burden',\n",
    "    'Fiscal Health':'EF_Fiscal Health',\n",
    "    'Business Freedom':'EF_Business Freedom',\n",
    "    'Monetary Freedom':'EF_Monetary Freedom',\n",
    "    'Labor Freedom':'EF_Labor Freedom',\n",
    "    'Financial Freedom':'EF_Financial Freedom',\n",
    "    'Investment Freedom':'EF_Investment Freedom',\n",
    "    'Trade Freedom':'EF_Trade Freedom'\n",
    "})\n",
    "\n",
    "# Calculating the 'EF_Overall Score'\n",
    "EF_features = ['EF_Property Rights', 'EF_Government Integrity', 'EF_Judicial Effectiveness',\n",
    "               'EF_Government Spending', 'EF_Tax Burden', 'EF_Fiscal Health',\n",
    "               'EF_Business Freedom', 'EF_Monetary Freedom', 'EF_Labor Freedom',\n",
    "               'EF_Financial Freedom', 'EF_Investment Freedom', 'EF_Trade Freedom']\n",
    "\n",
    "df_master['EF_Overall Score'] = df_master[EF_features].sum(axis=1) / 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country Name', 'Index Year', 'EF_Property Rights',\n",
       "       'EF_Government Integrity', 'EF_Judicial Effectiveness',\n",
       "       'EF_Government Spending', 'EF_Tax Burden', 'EF_Fiscal Health',\n",
       "       'EF_Business Freedom', 'EF_Monetary Freedom', 'EF_Labor Freedom',\n",
       "       'EF_Financial Freedom', 'EF_Investment Freedom', 'EF_Trade Freedom',\n",
       "       'GDP per capita (current USD)', 'Total population', 'Gini',\n",
       "       'Inflation CPI', 'Real interest rate', 'Labor force size',\n",
       "       'Trade (% of GDP)', 'Trade in services (% of GDP)',\n",
       "       'Under-5 mortality rate (per 1k live births)', 'Country Quintile',\n",
       "       'isLandLocked', 'n_accessToSea', 'Rail Density',\n",
       "       'Pctg of Rail Electrified', 'Area Size (km2)', 'Expanded EconZone Area',\n",
       "       'Amount of Ports', 'Distance from Equator', 'Average Temperature (C)',\n",
       "       'Death rates from disasters', 'H index (Academic Papers)',\n",
       "       'Arable Land pct', 'Qualified Labor Force pct',\n",
       "       'Human Development Index', 'Natural Resources', 'Migration Volume',\n",
       "       'Harmonized Test Scores', 'Amount of Country Neighbours',\n",
       "       'Amount of Major Conflicts_Since 1900', 'Population Density',\n",
       "       'Shared Borders (in pct)', 'Proportion of Rival Neighbours',\n",
       "       'Local Mean GDP per Capita', 'Local Mean GDP', 'Local Mean Gini',\n",
       "       'Religion_buddhism', 'Religion_christianity', 'Religion_folk',\n",
       "       'Religion_hinduism', 'Religion_islam', 'Religion_no religion',\n",
       "       'ClimateType_AF', 'ClimateType_AM', 'ClimateType_AW', 'ClimateType_BS',\n",
       "       'ClimateType_BW', 'ClimateType_CF', 'ClimateType_CW', 'ClimateType_DF',\n",
       "       'EF_Overall Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a019d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "years_delta = np.arange(1,26,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef37c6",
   "metadata": {},
   "source": [
    "### TimeSeriesDeltaChange()\n",
    "To assist us in this journey, let's create the function 'TimeSeriesDeltaChange'. A summary of it:\n",
    "\n",
    "**Purpose:** This function computes how recent changes in a predictor variable (like 'EF_Overall Score') relate to changes in a target variable (like 'GDP per capita') over various time ranges.\n",
    "\n",
    "**Working:**\n",
    "  - Cleans data and computes an Exponential Moving Average (EMA) for the predictor to calculate 'Recent Change in Predictor'.\n",
    "  - For each time period (delta), it:\n",
    "\t- Shifts the data by that period.\n",
    "\t- Calculates the percentage change for the target.\n",
    "\t- Fits a polynomial regression model using the difference from EMA as the predictor.\n",
    "\n",
    "**Output:** The function outputs an augmented DataFrame (df_withDeltas) that contains computed changes for each time period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a437920",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def TimeSeriesDeltaChange(\n",
    "        df,\n",
    "        predictors,\n",
    "        target = 'GDP per capita (current USD)',\n",
    "        quantiledTarget = 'Country Quintile',\n",
    "        timeField = 'Index Year',\n",
    "        mergeFields = ['Country Name', 'Index Year'],\n",
    "        timePeriods_delta = [1,4],\n",
    "        EMAdepth = 3\n",
    "    ):\n",
    "    '''\n",
    "    In a nutshell, this function analyzes time-series data using a time-slider-type analysis.\n",
    "    \n",
    "    predictor = the variable(s) name(s) you want to analyze.\n",
    "    target = the dependent variable name we want to predict for.\n",
    "    quantiledTarget = categorical data to split the data (useful for later visualization)\n",
    "    timeField = the name of the time column you're using\n",
    "    mergeFields = a list to define the Primary/Composite Key of the DataSet.\n",
    "    timePeriods_delta = list of delta ranges to test the data against\n",
    "    '''\n",
    "    \n",
    "    # Initializing Base DataFrame\n",
    "    cleaned_data = df[[\n",
    "                        mergeFields[0],\n",
    "                        mergeFields[1],\n",
    "                        *predictors,\n",
    "                        target,\n",
    "                        quantiledTarget\n",
    "                    ]].dropna()\n",
    "    \n",
    "    # Inverting negative features, so it's easier to interpret them in aggregation with other features.\n",
    "    cleaned_data['Gini'] = cleaned_data['Gini'] * - 1\n",
    "    cleaned_data['Local Mean Gini'] = cleaned_data['Local Mean Gini'] * - 1\n",
    "    cleaned_data['Inflation CPI'] = cleaned_data['Inflation CPI'] * - 1\n",
    "    cleaned_data['Death rates from disasters'] = cleaned_data['Death rates from disasters'] * - 1\n",
    "    cleaned_data['Real interest rate'] = cleaned_data['Real interest rate'] * - 1\n",
    "    cleaned_data['Under-5 mortality rate (per 1k live births)'] = cleaned_data['Under-5 mortality rate (per 1k live births)'] * - 1\n",
    "\n",
    "    for predictor in predictors:    \n",
    "        # Precompute the EMA and EMA diff for the predictor\n",
    "        cleaned_data[f'{predictor}_EMA_{EMAdepth}'] \\\n",
    "            = cleaned_data.groupby('Country Name')[predictor]\\\n",
    "                .transform(lambda x: x.ewm(span=EMAdepth, adjust=False).mean())   \n",
    "        \n",
    "        # Calculating the percentage change from predictor to its EMA\n",
    "        cleaned_data[f'{predictor}_diff_from_EMA'] \\\n",
    "            = ((cleaned_data[predictor] - cleaned_data[f'{predictor}_EMA_{EMAdepth}'])\n",
    "                / cleaned_data[f'{predictor}_EMA_{EMAdepth}']) * 100\n",
    "        \n",
    "        # Avoid Zero values on diff (Certain regressions break with 0 values here)\n",
    "        # Further on that, that is because certain fields, like Judicial Effectiveness, have late beginnings.\n",
    "        cleaned_data[f'{predictor}_diff_from_EMA']\\\n",
    "            = cleaned_data[f'{predictor}_diff_from_EMA'].transform(lambda x: np.random.normal(0, 0.000001) if x == 0 else x)\n",
    "        \n",
    "        # We don't need '{predictor}_EMA_{EMAdepth}' anymore, so let's drop it\n",
    "        cleaned_data = cleaned_data.drop(columns = [f'{predictor}_EMA_{EMAdepth}'])\n",
    "    \n",
    "    \n",
    "    df_withDeltas = cleaned_data.copy() #just initializing, for later appending\n",
    "    \n",
    "    # Loop over each year delta, compute & store the merged data, and fit a Regression Model\n",
    "    for delta in timePeriods_delta:\n",
    "        \n",
    "        # ----------------- Time Slider Effect Calculation -----------------\n",
    "        # Create a shifted dataframe to compute the changes\n",
    "        shifted_data = cleaned_data[[*mergeFields, target]].copy()\n",
    "        shifted_data[timeField] -= delta\n",
    "        \n",
    "        merged_data = pd.merge(\n",
    "            cleaned_data,\n",
    "            shifted_data[[*mergeFields, target]],  # Only include the shifted target variable\n",
    "            on=mergeFields,\n",
    "            suffixes=('', f'_plus_{delta}'),\n",
    "            indicator=False,\n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        # If there's no data for this range, go to the next iteration\n",
    "        if merged_data.shape[0] == 0:\n",
    "            print(f\"No overlapping data for any of the predictors with a time delta of {delta}. Skipping this delta.\")\n",
    "            continue\n",
    "        \n",
    "        # Compute the percentage change for target\n",
    "        merged_data[f'{target}_change_{delta}']\\\n",
    "            = ((merged_data[f'{target}_plus_{delta}']\\\n",
    "               - merged_data[target])\\\n",
    "               / merged_data[target]) * 100\n",
    "        \n",
    "        \n",
    "        # Merge results to df_withDeltas based on mergeFields\n",
    "        df_withDeltas = pd.merge(\n",
    "            df_withDeltas,\n",
    "            merged_data[[*mergeFields, f'{target}_change_{delta}']],\n",
    "            on=mergeFields,\n",
    "            how='left'\n",
    "        )\n",
    "    \n",
    "    return df_withDeltas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting numeric columns\n",
    "predictorsList = list(df_master.select_dtypes(include='number').columns)\n",
    "\n",
    "# Removing Time and Target Variables\n",
    "predictorsList.remove('Index Year')\n",
    "predictorsList.remove('GDP per capita (current USD)')\n",
    "\n",
    "# Removing variables that don't change through time (in our database)\n",
    "# They tend to be variables with low variability\n",
    "for col in predictorsList[13:]: # Skipping EF\n",
    "    if df_master[col].nunique() < 200:\n",
    "        predictorsList.remove(col)\n",
    "\n",
    "\n",
    "df_withDeltas = TimeSeriesDeltaChange(df_master, predictors=predictorsList, timePeriods_delta=years_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Stats from DF\n",
    "We'll iterate over each predictor, collect stats for all delta, and store the average value.\n",
    "\n",
    "For each iteration, we'll use the highest score from different Polynomial Degrees, to capture possible non-linear relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_withDeltas.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b28da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanR2ForLaggedValues(df_withDeltas = df_withDeltas, predictorsList = predictorsList, years_delta = years_delta, quintiled = None):\n",
    "\n",
    "    '''\n",
    "        For each feature, calculates the best fit in a polynomial (from degree 1 trough 6), and returns the mean R² score for all Delta Years.\n",
    "\n",
    "        df_withDeltas: DataFrame with lagged values data.\n",
    "        predictorsList: List of predictors we'll analyze\n",
    "        years_delta: List of lagged values we'll analyze\n",
    "        quintiled: selects quantile data from df_withDeltas\n",
    "    '''\n",
    "\n",
    "    # If True, selecting only the specified quintiled portion\n",
    "    if quintiled:\n",
    "        df_withDeltas = df_withDeltas[df_withDeltas['Country Quintile'] == quintiled]\n",
    "\n",
    "    POLYORDER = np.arange(1,7)\n",
    "    dict_r2_scores = {}\n",
    "\n",
    "    for predictor in predictorsList:\n",
    "        predictor_r2_scores = []\n",
    "\n",
    "        for degree in POLYORDER:\n",
    "            max_r2_scores = 0\n",
    "\n",
    "            for delta in years_delta:\n",
    "                # -------------------- Model Building & Fitting --------------------\n",
    "                X = df_withDeltas[f'{predictor}_diff_from_EMA'].values.reshape(-1, 1)   \n",
    "                y = df_withDeltas[f'GDP per capita (current USD)_change_{delta}']\n",
    "\n",
    "                # Polynomial Regression\n",
    "                poly = PolynomialFeatures(degree=degree)            \n",
    "                X_poly = poly.fit_transform(X)\n",
    "\n",
    "                # Using statsmodels to fit the model\n",
    "                model = sm.OLS(y, X_poly).fit()\n",
    "                R2_score = model.rsquared\n",
    "                #display(R2_score)\n",
    "\n",
    "                # Given p-value is less than 5%, store R²\n",
    "                if (model.pvalues < 0.05).all() and R2_score > max_r2_scores:\n",
    "                    max_r2_scores = R2_score\n",
    "\n",
    "\n",
    "\n",
    "            predictor_r2_scores.append(max_r2_scores)\n",
    "        \n",
    "        if predictor_r2_scores:\n",
    "            dict_r2_scores[predictor] = mean(predictor_r2_scores)\n",
    "        else:\n",
    "            dict_r2_scores[predictor] = None\n",
    "\n",
    "\n",
    "    # Result DataFrame\n",
    "    result_df = pd.DataFrame(list(dict_r2_scores.items()), columns=['Predictor', 'R2 Scores']).sort_values('R2 Scores', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Defining categories for each feature, so we can groupBy later\n",
    "    dict_featureGroupings = {\n",
    "        'geoPolitical':\n",
    "            ['Natural Resources','Arable Land pct','Migration Volume',\n",
    "            'Population Density', 'Total population'],\n",
    "\n",
    "        'Economic Freedom':\n",
    "            ['EF_Property Rights', 'EF_Government Integrity',\n",
    "        'EF_Judicial Effectiveness', 'EF_Government Spending', 'EF_Tax Burden',\n",
    "        'EF_Fiscal Health', 'EF_Business Freedom', 'EF_Monetary Freedom',\n",
    "        'EF_Labor Freedom', 'EF_Financial Freedom', 'EF_Investment Freedom',\n",
    "        'EF_Trade Freedom', 'EF_Overall Score'],\n",
    "\n",
    "        'Other Economic Factors':\n",
    "            ['Gini', 'Inflation CPI', 'Real interest rate', 'Labor force size',\n",
    "        f'Trade (% of GDP)',f'Trade in services (% of GDP)', 'Under-5 mortality rate (per 1k live births)',\n",
    "        'Death rates from disasters', 'Human Development Index'],\n",
    "\n",
    "        'Education & Research':\n",
    "            ['Qualified Labor Force pct','Harmonized Test Scores'],        \n",
    "\n",
    "        'Neighbour Quality':\n",
    "            ['Local Mean GDP per Capita','Local Mean GDP','Local Mean Gini']\n",
    "    }\n",
    "\n",
    "    # Inverting the dict to create a mapping from feature to group\n",
    "    feature_to_group = {feature: group for group, features in dict_featureGroupings.items() for feature in features}\n",
    "\n",
    "    # Adding the 'Predictor Group' column to the result DataFrame\n",
    "    result_df['Predictor Group'] = result_df['Predictor'].apply(lambda x: feature_to_group.get(x, 'Unknown')).astype('category')\n",
    "    result_df['Predictor'] = result_df['Predictor'].astype('category')\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R² Scores are low for every predictor group, which is expected. We're using a rudimentary method prediction-wise. Yet this gives us an important insight on a Causality hypothesis, since all of our data is using lagged values.\n",
    "\n",
    "As we can see, excluding features we can't/shouldn't directly influence politically (like Mean Neighbour GDP), Economic Freedom is still the most important factor for causing GDP per Capita. (Though Other Economic Factors are not far behind).\n",
    "\n",
    "Surprisingly, Education & Research features have really low R² Scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Causation Score by Predictor Group, for the whole Data'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor Group</th>\n",
       "      <th>R2 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neighbour Quality</td>\n",
       "      <td>0.037543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Economic Freedom</td>\n",
       "      <td>0.017451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Other Economic Factors</td>\n",
       "      <td>0.012229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>geoPolitical</td>\n",
       "      <td>0.011138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Education &amp; Research</td>\n",
       "      <td>0.001263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predictor Group  R2 Scores\n",
       "2       Neighbour Quality   0.037543\n",
       "0        Economic Freedom   0.017451\n",
       "3  Other Economic Factors   0.012229\n",
       "4            geoPolitical   0.011138\n",
       "1    Education & Research   0.001263"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_allQuintiles = meanR2ForLaggedValues()\n",
    "\n",
    "display('Causation Score by Predictor Group, for the whole Data')\n",
    "df_allQuintiles.groupby('Predictor Group', observed=False)['R2 Scores'].mean().reset_index(drop=False).sort_values('R2 Scores', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait. Simpson's Paradox could be at play here, so let's run the same data again, groupedBy quintiles.\n",
    "\n",
    "We'll average all results, so we can easily compare it with the previous table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mean Causation Score by Predictor Group, groupedBy each Quintile'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor Group</th>\n",
       "      <th>Mean R2 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neighbour Quality</td>\n",
       "      <td>0.048644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>geoPolitical</td>\n",
       "      <td>0.025114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Economic Freedom</td>\n",
       "      <td>0.016855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Other Economic Factors</td>\n",
       "      <td>0.015439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Education &amp; Research</td>\n",
       "      <td>0.002103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predictor Group  Mean R2 Scores\n",
       "2       Neighbour Quality        0.048644\n",
       "4            geoPolitical        0.025114\n",
       "0        Economic Freedom        0.016855\n",
       "3  Other Economic Factors        0.015439\n",
       "1    Education & Research        0.002103"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quintileList = ['Q1', 'Q2', 'Q3', 'Q4', 'Q5']\n",
    "\n",
    "df_quintiled = pd.DataFrame(columns=['Predictor Group', 'R2 Scores'])\n",
    "\n",
    "for q in quintileList:\n",
    "    #display(f'Causation Score by predictor Group, for Quintile: {q}')\n",
    "\n",
    "    # If you want to see each quintile data separately, uncomment the code below:\n",
    "    #display(meanR2ForLaggedValues(quintiled=q).groupby('Predictor Group', observed=False)['R2 Scores'].mean().reset_index(drop=False).sort_values('R2 Scores', ascending=False))\n",
    "\n",
    "    # merge quintile data into a single dataFrame\n",
    "    newQuant = meanR2ForLaggedValues(quintiled=q)\n",
    "    df_quintiled = df_quintiled.merge(newQuant, how='outer', on='Predictor Group', suffixes=('', f'_{q}'))\n",
    "    \n",
    "display('Mean Causation Score by Predictor Group, groupedBy each Quintile')\n",
    "# Calculating the Mean R2 Scores from Quintiled Data\n",
    "df_quintiled['Mean R2 Scores'] = (df_quintiled['R2 Scores_Q1'] +\n",
    "                                  df_quintiled['R2 Scores_Q2'] +\n",
    "                                  df_quintiled['R2 Scores_Q3'] +\n",
    "                                  df_quintiled['R2 Scores_Q4'] +\n",
    "                                  df_quintiled['R2 Scores_Q5']) / 5\n",
    "\n",
    "df_quintiled[['Predictor Group','Mean R2 Scores']].groupby('Predictor Group', observed=False)['Mean R2 Scores'].mean().reset_index(drop=False).sort_values('Mean R2 Scores', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor Group</th>\n",
       "      <th>R2 Scores_Q1</th>\n",
       "      <th>R2 Scores_Q2</th>\n",
       "      <th>R2 Scores_Q3</th>\n",
       "      <th>R2 Scores_Q4</th>\n",
       "      <th>R2 Scores_Q5</th>\n",
       "      <th>Mean R2 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neighbour Quality</td>\n",
       "      <td>0.042012</td>\n",
       "      <td>0.054810</td>\n",
       "      <td>0.043929</td>\n",
       "      <td>0.050250</td>\n",
       "      <td>0.052219</td>\n",
       "      <td>0.048644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>geoPolitical</td>\n",
       "      <td>0.034035</td>\n",
       "      <td>0.035805</td>\n",
       "      <td>0.011837</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>0.025630</td>\n",
       "      <td>0.025114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Economic Freedom</td>\n",
       "      <td>0.011576</td>\n",
       "      <td>0.021257</td>\n",
       "      <td>0.024189</td>\n",
       "      <td>0.016628</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.016855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Other Economic Factors</td>\n",
       "      <td>0.010213</td>\n",
       "      <td>0.019635</td>\n",
       "      <td>0.019537</td>\n",
       "      <td>0.015884</td>\n",
       "      <td>0.011925</td>\n",
       "      <td>0.015439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Education &amp; Research</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004776</td>\n",
       "      <td>0.002103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predictor Group  R2 Scores_Q1  R2 Scores_Q2  R2 Scores_Q3  \\\n",
       "2       Neighbour Quality      0.042012      0.054810      0.043929   \n",
       "4            geoPolitical      0.034035      0.035805      0.011837   \n",
       "0        Economic Freedom      0.011576      0.021257      0.024189   \n",
       "3  Other Economic Factors      0.010213      0.019635      0.019537   \n",
       "1    Education & Research      0.004537      0.000000      0.001203   \n",
       "\n",
       "   R2 Scores_Q4  R2 Scores_Q5  Mean R2 Scores  \n",
       "2      0.050250      0.052219        0.048644  \n",
       "4      0.018265      0.025630        0.025114  \n",
       "0      0.016628      0.010628        0.016855  \n",
       "3      0.015884      0.011925        0.015439  \n",
       "1      0.000000      0.004776        0.002103  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quintiled.groupby('Predictor Group', observed=False)[['R2 Scores_Q1','R2 Scores_Q2','R2 Scores_Q3','R2 Scores_Q4','R2 Scores_Q5','Mean R2 Scores']]\\\n",
    "        .mean().reset_index(drop=False).sort_values('Mean R2 Scores', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df_quintiled = pd.melt(df_quintiled[['Predictor Group','R2 Scores_Q1','R2 Scores_Q2','R2 Scores_Q3','R2 Scores_Q4','R2 Scores_Q5']], id_vars=['Predictor Group'], var_name='Description', value_name='Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdd7f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df_quintiled['Value'] = melted_df_quintiled['Value'].round(5)\n",
    "melted_df_quintiled = melted_df_quintiled.drop_duplicates(subset=['Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting data to flourish\n",
    "df_allQuintiles.groupby('Predictor Group', observed=False)['R2 Scores'].mean().reset_index(drop=False).sort_values('R2 Scores', ascending=False).to_csv(\"../Data_Sets/toFlourish/causation_allQuintiles.csv\",index=False)\n",
    "\n",
    "melted_df_quintiled.to_csv(\"../Data_Sets/toFlourish/causation_quintiled.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results shift a bit, but the overall conclusion remains.\n",
    "\n",
    "Economic Freedom is the most important, closely followed by Other Economic Factors, and Education & Research is considerably behind every Predictor Group."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
