{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Scimagojr\n",
    "df_academicRelevance = pd.read_csv(\"..\\\\Data_Sets\\\\originalData\\\\academic_relevance_1996-2022.csv\")\n",
    "\n",
    "# From OurWorldInData\n",
    "df_HDI = pd.read_csv(\"..\\\\Data_Sets\\\\originalData\\\\human-development-index.csv\")\n",
    "df_migrants = pd.read_csv(\"..\\\\Data_Sets\\\\originalData\\\\migrant-stock-total.csv\")\n",
    "df_naturalResources = pd.read_csv(\"..\\\\Data_Sets\\\\originalData\\\\naturalResourcesWealth.csv\")\n",
    "df_educationQuality = pd.read_csv(\"..\\\\Data_Sets\\\\originalData\\\\education_quality_by_outcome.csv\")\n",
    "\n",
    "# From World Bank\n",
    "df_arableLand = pd.read_csv(\"..\\\\Data_Sets\\\\originalData\\\\arableLand.csv\", skiprows=4)\n",
    "df_qualifiedLaborForce = pd.read_csv(\"..\\\\Data_Sets\\\\originalData\\\\Labor_force_with_advanced_education.csv\", skiprows=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data processed in other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_climateData = pd.read_csv(\"..\\\\Data_Sets\\\\processed\\\\addData_climateData.csv\")\n",
    "df_countriesSize_regions = pd.read_csv(\"..\\\\Data_Sets\\\\processed\\\\addData_countriesSize_Regions.csv\")\n",
    "df_fromWiki = pd.read_csv(\"..\\\\Data_Sets\\\\processed\\\\addData_fromWiki.csv\")\n",
    "df_economicFreedom = pd.read_csv(\"..\\\\Data_Sets\\\\processed\\\\economicData_1995-2022.csv\")\n",
    "df_naturalDisasters = pd.read_csv(\"..\\\\Data_Sets\\\\processed\\\\addData_disasterData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Data - Part 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only necessary columns from our main DataSet\n",
    "df_master = df_economicFreedom[list(df_economicFreedom)[0:15] +\n",
    "                               ['GDP per capita (current USD)'] +\n",
    "                               list(df_economicFreedom)[19:27] +\n",
    "                               ['Under-5 mortality rate (per 1k live births)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country Name', 'Index Year', 'Overall Score', 'Property Rights',\n",
       "       'Government Integrity', 'Judicial Effectiveness', 'Government Spending',\n",
       "       'Tax Burden', 'Fiscal Health', 'Business Freedom', 'Monetary Freedom',\n",
       "       'Labor Freedom', 'Financial Freedom', 'Investment Freedom',\n",
       "       'Trade Freedom', 'GDP per capita (current USD)', 'Total population',\n",
       "       'Land area (sq. km)', 'Gini', 'Inflation CPI', 'Real interest rate',\n",
       "       'Labor force size', 'Trade (% of GDP)', 'Trade in services (% of GDP)',\n",
       "       'Under-5 mortality rate (per 1k live births)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country Name', 'Borders Length (in KM)', 'Neighbouring Countries',\n",
       "       'isLandLocked', 'n_accessToSea', 'Values', 'Rail Density',\n",
       "       'Pctg of Rail Electrified', 'Warred Against', 'Area Size (km2)',\n",
       "       'Expanded EconZone Area', 'Amount of Ports', 'Distance from Equator',\n",
       "       'Majoritary Religions'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_master = df_master.merge(df_fromWiki, how='left', on=['Country Name'])\n",
    "\n",
    "display(df_fromWiki.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country Name', 'Shape_Leng', 'Shape_Area', 'SubRegion', 'Region'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_master = df_master.merge(df_countriesSize_regions[['Country Name', 'Shape_Leng', 'Region']], how='left', on=['Country Name'])\n",
    "\n",
    "display(df_countriesSize_regions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country Name', 'Climate Type', 'Average Temperature (C)'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_master = df_master.merge(df_climateData, how='left', on=['Country Name'])\n",
    "\n",
    "display(df_climateData.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to reshape df_naturalDisasters before merging it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country Name', 'Index Year', 'Death rates from disasters'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_naturalDisasters.rename(columns={\n",
    "    \"Index Year (Decade)\": 'Index Year'\n",
    "}, inplace=True)\n",
    "\n",
    "# Setting the minimum year in our data [note: 'Death rates from disasters' in 1990 was already halved, to look like half a decade]\n",
    "df_naturalDisasters.loc[df_naturalDisasters['Index Year'] == 1990, ['Index Year']] = 1995\n",
    "\n",
    "# Transforming Decade Data into Yearly data\n",
    "df_naturalDisasters.loc[df_naturalDisasters['Index Year'] == 1995, ['Death rates from disasters']] /= 5\n",
    "df_naturalDisasters.loc[df_naturalDisasters['Index Year'] == 2000, ['Death rates from disasters']] /= 10\n",
    "df_naturalDisasters.loc[df_naturalDisasters['Index Year'] == 2010, ['Death rates from disasters']] /= 10\n",
    "\n",
    "# List of years to add\n",
    "years_to_add = list(range(1996, 2022+1))\n",
    "years_to_add.remove(2000)\n",
    "years_to_add.remove(2010)\n",
    "\n",
    "new_rows = []\n",
    "for year in years_to_add:\n",
    "    for country in df_naturalDisasters['Country Name'].unique():\n",
    "        new_rows.append({\n",
    "            'Country Name': country,\n",
    "            'Index Year': year,\n",
    "            'Death rates from disasters': np.nan\n",
    "            })\n",
    "        \n",
    "# Combining data\n",
    "df_temp = pd.DataFrame(new_rows)\n",
    "df_naturalDisasters = pd.concat([df_naturalDisasters, df_temp], ignore_index=True)\n",
    "\n",
    "# Sorting By year, then by Country\n",
    "df_naturalDisasters = df_naturalDisasters.sort_values(by=['Country Name', 'Index Year']).reset_index(drop=True)\n",
    "\n",
    "# Interpolating 'Death rates from disasters'\n",
    "df_naturalDisasters['Death rates from disasters'] = df_naturalDisasters.groupby('Country Name')['Death rates from disasters'].apply(lambda group: group.ffill(axis=0)).reset_index(drop=True)\n",
    "\n",
    "# Doing the actual merging\n",
    "df_master = df_master.merge(df_naturalDisasters, how='left', on=['Country Name', 'Index Year'])\n",
    "\n",
    "display(df_naturalDisasters.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Original DataSets before merging them into df_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzySearchName(name, refNames=df_master, score_threshold = 87):\n",
    "    '''\n",
    "        Given a country name, returns the closest match from refNames using fuzzy search.\n",
    "        If no close match is found, it returns \"PLEASE FILL MANUALLY\".\n",
    "    '''\n",
    "    \n",
    "    # If the name is empty or null, return \"UNKNOWN\"\n",
    "    if pd.isna(name) or not name.strip():\n",
    "        return \"UNKNOWN\"\n",
    "\n",
    "    exceptions = {\n",
    "        \"Kyrgyzstan\": \"Kyrgyz Republic\",\n",
    "        \"Congo\": \"Republic of Congo\",\n",
    "        'Congo, Rep.': \"Republic of Congo\",\n",
    "        'Congo, Dem. Rep.': \"Democratic Republic of Congo\",\n",
    "        'Democratic Republic Of The Congo': 'Democratic Republic of Congo',\n",
    "        \"Czechia\": \"Czech Republic\",\n",
    "        \"Slovakia\": \"Slovak Republic\",\n",
    "        \"Macao Sar, China\": \"Macau\",\n",
    "        \"Macao\": \"Macau\",\n",
    "        'Republic Of The Congo': 'Republic of Congo',\n",
    "        'Swaziland': 'Eswatini',\n",
    "        'Korea, Rep.': 'South Korea',\n",
    "        \"Korea, Dem. People'S Rep.\": 'North Korea',\n",
    "        'St. Vincent and the Grenadines': 'Saint Vincent and the Grenadines',\n",
    "        'Lao Pdr': 'Laos',\n",
    "        \"Hong Kong Sar, China\": \"Hong Kong\",\n",
    "        'Cabo Verde': 'Cape Verde',\n",
    "        'Egypt, Arab Rep.': 'Egypt',\n",
    "        'Turkiye': 'Turkey',\n",
    "        'St. Lucia': 'Saint Lucia',\n",
    "        'East Timor': 'Timor-Leste'    \n",
    "    }\n",
    "    \n",
    "    if name in exceptions:\n",
    "        return exceptions[name]\n",
    "    \n",
    "    match, score = process.extractOne(name, refNames['Country Name'].unique())\n",
    "\n",
    "    # If a close match is found, return the match\n",
    "    if score > score_threshold:\n",
    "        return match\n",
    "    \n",
    "    # If no close match is found, ask for manual input\n",
    "    return \"PLEASE FILL MANUALLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanedNamesMask(df, column = str()):\n",
    "\n",
    "    '''\n",
    "        Takes a dataFrame (and its column with Country Names), and returns a mask of rows to exclude\n",
    "    '''\n",
    "\n",
    "    removeList = [\n",
    "    'British Indian Ocean Territory', 'Africa', 'Europe', 'North America', 'South America', 'Asia', 'Oceania',\n",
    "    'Sint Maarten (Dutch part)', 'Saint Martin (French Part)', 'Antigua and Barbuda',\n",
    "    'Netherlands Antilles', 'Northern Mariana Islands', 'Saint Barthelemy',\n",
    "    'Saint Helena, Ascension and Tristan da Cunha', 'Saint Kitts and Nevis',\n",
    "    'Serbia-Montenegro', \"Turks and Caicos Islands\", 'United States Virgin Islands',\n",
    "    'Wallis and Futuna', 'Yugoslavia', 'Cocos (Keeling) Islands', 'Isle Of Man', 'South Georgia And South Sandwich Islands',\n",
    "    'South Sudan','United States Minor Outlying Islands','Saint Pierre And Miquelon', 'American Samoa',\n",
    "    'Falkland Islands (Malvinas)', 'Virgin Islands (British)', 'Saint Martin (Dutch)', 'Saint Martin (French)',\n",
    "    'Heard Island And Mcdonald Islands', 'South Georgia And The South Sandwich Islands', 'Republic Of South Sudan',\n",
    "    'Somalia'\n",
    "    ]\n",
    "\n",
    "    df[column] = df[column].str.strip().str.title()\n",
    "    removeList = [country.title() for country in removeList]\n",
    "\n",
    "    mask = ~df[column].isin(removeList)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzyNamesFix(df, oldName = 'Country Name', newName='New Country Name'):\n",
    "    '''\n",
    "        Processes a DataFrame's country names to the standard we're using in this project.\n",
    "        Uses to custom functions: fuzzySearchName() and cleanedNamesMask()\n",
    "    '''\n",
    "\n",
    "    # Remove rows with problematic names\n",
    "    mask = cleanedNamesMask(df, str(oldName))\n",
    "    df = df[mask].copy()\n",
    "    display(f'% of included countries in mask: {mask.mean()}')\n",
    "\n",
    "    # Fuzzy Search replacement\n",
    "    df[str(newName)] = df[str(oldName)].apply(fuzzySearchName)\n",
    "\n",
    "    # Excluding \"PLEASE FILL MANUALLY\"\n",
    "    df = df[~df[str(newName)].isin([\"PLEASE FILL MANUALLY\"])]\n",
    "\n",
    "    # Checking for duplicated countries\n",
    "    display('','Checking for duplicated countries')\n",
    "    display(df[str(newName)].describe(include=['object']), '')\n",
    "\n",
    "    # Casting New Country Name to Country Name\n",
    "    df[str(oldName)] = df[str(newName)].copy()\n",
    "\n",
    "    # Drop unused names column (new name)\n",
    "    df.drop(columns=[str(newName)], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolateMiddle(series, timeField_series, n_times=0, extrapolate=4):\n",
    "    '''\n",
    "    Essentially, just fill the middle values (n_times) for any given Series, and project past/future for (extrapolate) times.\n",
    "    \n",
    "    series: the series to interpolate\n",
    "    timeField_series: corresponding time data for the series\n",
    "    n_times: interpolation reach. If zero, find maximum value based on 'field'.\n",
    "    extrapolate: how much time to project past \"middle data\"\n",
    "    '''\n",
    "    \n",
    "    # If invalid, we'll pick a value that works in this DataSet.\n",
    "    if n_times <= 0:\n",
    "        n_times = int((2022-1960)/2)\n",
    "    \n",
    "    # Setting points to help determine 'middle' data\n",
    "    earliest_time = timeField_series.loc[series.notna()].min()\n",
    "    latest_time = timeField_series.loc[series.notna()].max()\n",
    "    \n",
    "    # If there's no non-NaN value, return the Series as-is\n",
    "    if pd.isna(earliest_time) or pd.isna(latest_time):\n",
    "        return series\n",
    "    \n",
    "    # Only interpolate what has been defined as \"middle data\"\n",
    "    maskedtimes = (timeField_series >= earliest_time)&(timeField_series <= latest_time)    \n",
    "    temp_series = series[maskedtimes]\n",
    "    temp_series.interpolate(method='linear', limit=n_times, limit_direction='both', inplace=True)    \n",
    "    \n",
    "    # Update the original Series with interpolated middle data\n",
    "    series[maskedtimes] = temp_series\n",
    "    \n",
    "    if extrapolate > 0:\n",
    "        temp_series = series\n",
    "        temp_series.interpolate(method='linear', limit=extrapolate, limit_direction='both', inplace=True)\n",
    "    \n",
    "        # Update the original Series (on extrapolate step)\n",
    "        series = temp_series\n",
    "    \n",
    "    return series\n",
    "\n",
    "def process_group(group, column, *args, **kwargs):\n",
    "    timeField_series = group['Index Year']\n",
    "    group[column] = interpolateMiddle(group[column], timeField_series, *args, **kwargs)\n",
    "    return group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Academic Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_academicRelevance.rename(columns={'Country': 'Country Name', 'H index': 'H index (Academic Papers)'}, inplace=True)\n",
    "\n",
    "df_academicRelevance = df_academicRelevance[['Country Name', 'H index (Academic Papers)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'% of included countries in mask: 0.9218106995884774'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Checking for duplicated countries'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count               182\n",
       "unique              182\n",
       "top       United States\n",
       "freq                  1\n",
       "Name: New Country Name, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Excluding non-relevant countries to our DataSet\n",
    "df_academicRelevance = fuzzyNamesFix(df_academicRelevance, 'Country Name')\n",
    "\n",
    "# Sorting\n",
    "df_academicRelevance = df_academicRelevance.sort_values(by=['Country Name']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually adding Kosovo. Source: https://xk.h-index.com/en\n",
    "# Manually adding North Macedonia. Source: https://www.adscientificindex.com/?country_code=mk\n",
    "\n",
    "df_temp = pd.DataFrame({\n",
    "    'Country Name': ['Kosovo', 'North Macedonia'],\n",
    "    'H index (Academic Papers)': [147, 59]\n",
    "})\n",
    "\n",
    "df_academicRelevance = pd.concat([df_academicRelevance, df_temp], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Names we should exclude: set()'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Names that are still missing: set()'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_A = set(df_academicRelevance['Country Name'].unique())\n",
    "set_B = set(df_master['Country Name'].unique())\n",
    "\n",
    "display(f'Names we should exclude: {set_A - set_B}')\n",
    "display(f'Names that are still missing: {set_B - set_A}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country Name', 'H index (Academic Papers)'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_master = df_master.merge(df_academicRelevance, how='left', on=['Country Name'])\n",
    "\n",
    "display(df_academicRelevance.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### World Bank:\n",
    "\n",
    "Arable Land and Qualified Work Foce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'% of included countries in mask: 0.9661654135338346'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Checking for duplicated countries'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count             183\n",
       "unique            183\n",
       "top       Afghanistan\n",
       "freq                1\n",
       "Name: New Country Name, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'% of included countries in mask: 0.9661654135338346'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Checking for duplicated countries'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count             183\n",
       "unique            183\n",
       "top       Afghanistan\n",
       "freq                1\n",
       "Name: New Country Name, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Excluding non-relevant countries to our DataSet\n",
    "df_arableLand = fuzzyNamesFix(df_arableLand, 'Country Name')\n",
    "df_qualifiedLaborForce = fuzzyNamesFix(df_qualifiedLaborForce, 'Country Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to transpose the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [str(year) for year in range(1995, 2022+1)]  # This selects the columns representing 1995 through 2022\n",
    "df_arableLand = df_arableLand[['Country Name'] + years]\n",
    "df_qualifiedLaborForce = df_qualifiedLaborForce[['Country Name'] + years]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arableLand = df_arableLand.melt(id_vars=[\"Country Name\"], \n",
    "                               value_vars=list(map(str, range(1995, 2023))),\n",
    "                               var_name=\"Index Year\", \n",
    "                               value_name=\"Arable Land pct\")\n",
    "\n",
    "df_qualifiedLaborForce = df_qualifiedLaborForce.melt(id_vars=[\"Country Name\"], \n",
    "                               value_vars=list(map(str, range(1995, 2023))),\n",
    "                               var_name=\"Index Year\", \n",
    "                               value_name=\"Qualified Labor Force pct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Index Year to int\n",
    "df_arableLand['Index Year'] = df_arableLand['Index Year'].astype('int')\n",
    "df_qualifiedLaborForce['Index Year'] = df_qualifiedLaborForce['Index Year'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_arableLand Stats'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Names we should exclude: set()'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Names that are still missing: set()'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5124, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('df_arableLand Stats')\n",
    "set_A = set(df_arableLand['Country Name'].unique())\n",
    "set_B = set(df_master['Country Name'].unique())\n",
    "\n",
    "display(f'Names we should exclude: {set_A - set_B}')\n",
    "display(f'Names that are still missing: {set_B - set_A}')\n",
    "\n",
    "\n",
    "display(df_arableLand.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_qualifiedLaborForce Stats'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Names we should exclude: set()'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Names that are still missing: set()'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5124, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('df_qualifiedLaborForce Stats')\n",
    "set_A = set(df_qualifiedLaborForce['Country Name'].unique())\n",
    "set_B = set(df_master['Country Name'].unique())\n",
    "\n",
    "display(f'Names we should exclude: {set_A - set_B}')\n",
    "display(f'Names that are still missing: {set_B - set_A}')\n",
    "\n",
    "\n",
    "display(df_qualifiedLaborForce.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country Name', 'Index Year', 'Arable Land pct'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Country Name', 'Index Year', 'Qualified Labor Force pct'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_master = df_master.merge(df_arableLand, how='left', on=['Country Name', 'Index Year'])\n",
    "df_master = df_master.merge(df_qualifiedLaborForce, how='left', on=['Country Name', 'Index Year'])\n",
    "\n",
    "display(df_arableLand.columns)\n",
    "display(df_qualifiedLaborForce.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our World in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['Human capital', 'Produced capital', 'Net foreign assets'] # We need to nesure that we're only capturing Natural Resources Value\n",
    "df_naturalResources = df_naturalResources.drop(columns=cols_to_drop)\n",
    "\n",
    "# Now let's add every col in a new col\n",
    "df_naturalResources['Natural Resources'] = df_naturalResources.iloc[:, -6:].sum(axis=1)\n",
    "df_naturalResources = df_naturalResources[['Entity', 'Code', 'Year', 'Natural Resources']]\n",
    "\n",
    "# Let's select only the years we need\n",
    "df_HDI = df_HDI.loc[df_HDI['Year'] >= 1995, :]\n",
    "df_migrants = df_migrants.loc[df_migrants['Year'] >= 1995, :]\n",
    "df_naturalResources = df_naturalResources.loc[df_naturalResources['Year'] >= 1995, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of years to add | educationQuality\n",
    "years_to_add = list(range(1995, 2022+1))\n",
    "years_to_add.remove(2010)\n",
    "years_to_add.remove(2017)\n",
    "years_to_add.remove(2018)\n",
    "years_to_add.remove(2020)\n",
    "\n",
    "new_rows_educationQuality = []\n",
    "for year in years_to_add:\n",
    "    for country in df_educationQuality['Entity'].unique():\n",
    "        new_rows_educationQuality.append({\n",
    "            'Entity': country,\n",
    "            'Year': year,\n",
    "            'Harmonized Test Scores': np.nan\n",
    "            })\n",
    "\n",
    "# List of years to add | df_naturalResources\n",
    "years_to_add = list(range(1995, 2022+1))\n",
    "years_to_add.remove(1995)\n",
    "years_to_add.remove(2000)\n",
    "years_to_add.remove(2005)\n",
    "years_to_add.remove(2010)\n",
    "years_to_add.remove(2014)\n",
    "\n",
    "new_rows_naturalResources = []\n",
    "for year in years_to_add:\n",
    "    for country in df_naturalResources['Entity'].unique():\n",
    "        new_rows_naturalResources.append({\n",
    "            'Entity': country,\n",
    "            'Year': year,\n",
    "            'Natural Resources': np.nan\n",
    "            })\n",
    "\n",
    "# List of years to add | Migrants\n",
    "years_to_add = list(range(1995, 2022+1))\n",
    "years_to_add.remove(1995)\n",
    "years_to_add.remove(2000)\n",
    "years_to_add.remove(2005)\n",
    "years_to_add.remove(2010)\n",
    "years_to_add.remove(2015)\n",
    "\n",
    "new_rows_migrants = []\n",
    "for year in years_to_add:\n",
    "    for country in df_migrants['Entity'].unique():\n",
    "        new_rows_migrants.append({\n",
    "            'Entity': country,\n",
    "            'Year': year,\n",
    "            'International migrant stock, total': np.nan\n",
    "            })\n",
    "\n",
    "# List of years to add | df_HDI\n",
    "years_to_add = [2022]\n",
    "\n",
    "new_rows_HDI = []\n",
    "for year in years_to_add:\n",
    "    for country in df_HDI['Entity'].unique():\n",
    "        new_rows_HDI.append({\n",
    "            'Entity': country,\n",
    "            'Year': year,\n",
    "            'Human Development Index': np.nan\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining data\n",
    "df_temp = pd.DataFrame(new_rows_educationQuality)\n",
    "df_educationQuality = pd.concat([df_educationQuality, df_temp], ignore_index=True)\n",
    "\n",
    "df_temp = pd.DataFrame(new_rows_naturalResources)\n",
    "df_naturalResources = pd.concat([df_naturalResources, df_temp], ignore_index=True)\n",
    "\n",
    "df_temp = pd.DataFrame(new_rows_migrants)\n",
    "df_migrants = pd.concat([df_migrants, df_temp], ignore_index=True)\n",
    "\n",
    "df_temp = pd.DataFrame(new_rows_HDI)\n",
    "df_HDI = pd.concat([df_HDI, df_temp], ignore_index=True)\n",
    "\n",
    "# Sorting By year, then by Country\n",
    "df_educationQuality = df_educationQuality.sort_values(by=['Entity', 'Year']).reset_index(drop=True)\n",
    "\n",
    "df_naturalResources = df_naturalResources.sort_values(by=['Entity', 'Year']).reset_index(drop=True)\n",
    "\n",
    "df_migrants = df_migrants.sort_values(by=['Entity', 'Year']).reset_index(drop=True)\n",
    "\n",
    "df_HDI = df_HDI.sort_values(by=['Entity', 'Year']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Code column before merging\n",
    "df_educationQuality = df_educationQuality.drop(columns=['Code'])\n",
    "df_naturalResources = df_naturalResources.drop(columns=['Code'])\n",
    "df_migrants = df_migrants.drop(columns=['Code'])\n",
    "df_HDI = df_HDI.drop(columns=['Code'])\n",
    "\n",
    "# Now let's merge them into a temporary DataFrame\n",
    "df_OWinData = df_HDI.merge(df_naturalResources,how='outer',on=['Entity', 'Year'])\n",
    "df_OWinData = df_OWinData.merge(df_migrants,how='outer',on=['Entity', 'Year'])\n",
    "df_OWinData = df_OWinData.merge(df_educationQuality,how='outer',on=['Entity', 'Year'])\n",
    "\n",
    "df_OWinData.rename(columns={\n",
    "    'Entity': 'Country Name',\n",
    "    'Year': 'Index Year',\n",
    "    'International migrant stock, total': 'Migration Volume',\n",
    "    'Humand Development Index': 'HDI'    \n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing Country Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'% of included countries in mask: 0.9358732005234841'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Checking for duplicated countries'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count            5123\n",
       "unique            183\n",
       "top       Afghanistan\n",
       "freq               28\n",
       "Name: New Country Name, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Names we should exclude: set()'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Names that are still missing: set()'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_OWinData = fuzzyNamesFix(df_OWinData, 'Country Name')\n",
    "\n",
    "#df_OWinData.to_csv(\".\\\\temp.csv\")\n",
    "\n",
    "set_A = set(df_OWinData['Country Name'].unique())\n",
    "set_B = set(df_master['Country Name'].unique())\n",
    "\n",
    "display(f'Names we should exclude: {set_A - set_B}')\n",
    "display(f'Names that are still missing: {set_B - set_A}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating Human Development Index...\n",
      "Interpolating Natural Resources...\n",
      "Interpolating Migration Volume...\n",
      "Interpolating Harmonized Test Scores...\n"
     ]
    }
   ],
   "source": [
    "to_interpolate = ['Human Development Index', 'Natural Resources', 'Migration Volume', 'Harmonized Test Scores']\n",
    "\n",
    "# Process each column in DataFrame\n",
    "for col in to_interpolate:\n",
    "    print(f'Interpolating {col}...')\n",
    "    df_OWinData = df_OWinData.groupby(by=['Country Name']).apply(lambda group: process_group(group, col, n_times=100, extrapolate=100)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Names we should exclude: set()'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Names that are still missing: set()'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_A = set(df_OWinData['Country Name'].unique())\n",
    "set_B = set(df_master['Country Name'].unique())\n",
    "\n",
    "display(f'Names we should exclude: {set_A - set_B}')\n",
    "display(f'Names that are still missing: {set_B - set_A}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final merge and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = df_master.merge(df_OWinData,how='left',on=['Country Name', 'Index Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.to_csv(f\"..\\\\Data_Sets\\\\processed\\\\mergedData_toClean_1995-2022.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EconStats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
