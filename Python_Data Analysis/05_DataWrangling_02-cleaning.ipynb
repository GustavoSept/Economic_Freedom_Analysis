{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "import ast # used to convert strings to Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = pd.read_csv(\"..\\\\Data_Sets\\\\processed\\\\mergedData_toClean_1995-2022.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolateMiddle(series, timeField_series, n_times=0, extrapolate=4):\n",
    "    '''\n",
    "    Essentially, just fill the middle values (n_times) for any given Series, and project past/future for (extrapolate) times.\n",
    "    \n",
    "    series: the series to interpolate\n",
    "    timeField_series: corresponding time data for the series\n",
    "    n_times: interpolation reach. If zero, find maximum value based on 'field'.\n",
    "    extrapolate: how much time to project past \"middle data\"\n",
    "    '''\n",
    "    \n",
    "    # If invalid, we'll pick a value that works in this DataSet.\n",
    "    if n_times <= 0:\n",
    "        n_times = int((2022-1960)/2)\n",
    "    \n",
    "    # Setting points to help determine 'middle' data\n",
    "    earliest_time = timeField_series.loc[series.notna()].min()\n",
    "    latest_time = timeField_series.loc[series.notna()].max()\n",
    "    \n",
    "    # If there's no non-NaN value, return the Series as-is\n",
    "    if pd.isna(earliest_time) or pd.isna(latest_time):\n",
    "        return series\n",
    "    \n",
    "    # Only interpolate what has been defined as \"middle data\"\n",
    "    maskedtimes = (timeField_series >= earliest_time)&(timeField_series <= latest_time)    \n",
    "    temp_series = series[maskedtimes]\n",
    "    temp_series.interpolate(method='linear', limit=n_times, limit_direction='both', inplace=True)    \n",
    "    \n",
    "    # Update the original Series with interpolated middle data\n",
    "    series[maskedtimes] = temp_series\n",
    "    \n",
    "    if extrapolate > 0:\n",
    "        temp_series = series\n",
    "        temp_series.interpolate(method='linear', limit=extrapolate, limit_direction='both', inplace=True)\n",
    "    \n",
    "        # Update the original Series (on extrapolate step)\n",
    "        series = temp_series\n",
    "    \n",
    "    return series\n",
    "\n",
    "def process_group(group, column, *args, **kwargs):\n",
    "    timeField_series = group['Index Year']\n",
    "    group[column] = interpolateMiddle(group[column], timeField_series, *args, **kwargs)\n",
    "    return group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Cleaning procedures\n",
    "There's still a few things left to clean in this DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll drop 'Land area (sq. km)' as we already have a column with that information\n",
    "df_master.drop('Land area (sq. km)', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Checking for duplicated countries'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count        4767\n",
       "unique        183\n",
       "top       Albania\n",
       "freq           28\n",
       "Name: Country Name, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking for duplicated countries\n",
    "display('Checking for duplicated countries')\n",
    "display(df_master['Country Name'].describe(include=['object']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Filling\n",
    "We'll extrapolate some more values, and then evaluate which rows we'll have to drop depending on the column it's value is missing from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master['Borders Length (in KM)'] = df_master['Borders Length (in KM)'].str.replace(',', '')\n",
    "df_master['Borders Length (in KM)'] = df_master['Borders Length (in KM)'].astype('float').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_master.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_interpolate_easy = list(df_master.columns)[15:] # skipping Economic Freedom cols\n",
    "\n",
    "# These are the fields that lack 1000 or more rows. We'll need to look at them more carefully before interpolating\n",
    "to_interpolate_easy.remove('Gini')\n",
    "to_interpolate_easy.remove('Real interest rate')\n",
    "to_interpolate_easy.remove('Qualified Labor Force pct')\n",
    "to_interpolate_easy.remove('Natural Resources')\n",
    "\n",
    "# It doesn't make sense to interpolate these fields, as they are categorical\n",
    "to_interpolate_easy.remove('Neighbouring Countries')\n",
    "to_interpolate_easy.remove('Majoritary Religions')\n",
    "to_interpolate_easy.remove('Warred Against')\n",
    "to_interpolate_easy.remove('Climate Type')\n",
    "to_interpolate_easy.remove('Region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each column in DataFrame\n",
    "for col in to_interpolate_easy:\n",
    "    #print(f'Interpolating {col}...')\n",
    "    df_master = df_master.groupby(by=['Country Name']).apply(lambda group: process_group(group, col, n_times=100, extrapolate=100)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual filling\n",
    "We'll treat the rest on a case by case basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fiscal Health, Judicial Effectiveness and Labor Freedom: They're Economic Freedom metrics that didn't start from 1995. So we'll extrapolate 4 more years, and then fill the rest with whatever the overall score is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_master[df_master['Country Name'] == 'Jordan'].loc[:, ['Country Name','Index Year','Qualified Labor Force pct', 'Gini']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_interpolate_EF = list(df_master.columns)[2:15]\n",
    "\n",
    "# Forcing Overall Score calculation when overall score is missing\n",
    "average_values = df_master[df_master.columns[3:15]].mean(axis=1)\n",
    "df_master['Overall Score'] = df_master['Overall Score'].fillna(average_values)\n",
    "\n",
    "for col in to_interpolate_EF:    \n",
    "    df_master = df_master.groupby(by=['Country Name']).apply(lambda group: process_group(group, col, n_times=100, extrapolate=4)).reset_index(drop=True)    \n",
    "\n",
    "    df_master[str(col)] = df_master[str(col)].fillna(df_master['Overall Score'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini, Real interest rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll extrapolate 6 years, then fill the rest with the average of (self and region).\n",
    "to_interpolate_giniInterest = ['Gini', 'Real interest rate']\n",
    "\n",
    "\n",
    "for col in to_interpolate_giniInterest:    \n",
    "    df_master = df_master.groupby(by=['Country Name']).apply(lambda group: process_group(group, col, n_times=100, extrapolate=6)).reset_index(drop=True)    \n",
    "\n",
    "\n",
    "# Filling the remainder with the average of self values and regional values.\n",
    "\n",
    "country_avg = df_master.groupby('Country Name')[to_interpolate_giniInterest].transform('mean')\n",
    "country_avg.fillna(0, inplace=True)\n",
    "region_avg = df_master.groupby('Region')[to_interpolate_giniInterest].transform('mean')\n",
    "combined_avg = (country_avg + region_avg) / 2\n",
    "\n",
    "df_master[to_interpolate_giniInterest] = df_master[to_interpolate_giniInterest].fillna(combined_avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualified Labor Force pct, Natural Resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll extrapolate all years, then fill the rest with the average of (self and region).\n",
    "to_interpolate_laborFNatRes = ['Qualified Labor Force pct', 'Natural Resources']\n",
    "\n",
    "\n",
    "for col in to_interpolate_laborFNatRes:    \n",
    "    df_master = df_master.groupby(by=['Country Name']).apply(lambda group: process_group(group, col, n_times=100, extrapolate=30)).reset_index(drop=True)    \n",
    "\n",
    "\n",
    "# Filling the remainder with the average of self values and regional values.\n",
    "\n",
    "country_avg = df_master.groupby('Country Name')[to_interpolate_laborFNatRes].transform('mean')\n",
    "country_avg.fillna(0, inplace=True)\n",
    "region_avg = df_master.groupby('Region')[to_interpolate_laborFNatRes].transform('mean')\n",
    "combined_avg = (country_avg + region_avg) / 2\n",
    "\n",
    "df_master[to_interpolate_laborFNatRes] = df_master[to_interpolate_laborFNatRes].fillna(combined_avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually inserting North Korea's GDP per Capita information\n",
    "Source: http://data.un.org/Data.aspx?q=korea+gdp&d=SNAAMA&f=grID:101;currID:USD;pcFlag:1;crID:408,410"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_per_capita_values = [\n",
    "    222, 479, 462, 456, 452, 462, 476, 468, 471, 473,\n",
    "    548, 576, 599, 553, 497, 573, 642, 648, 672, 702,\n",
    "    654, 671, 690, 692, 643, 621, 654, 666]\n",
    "\n",
    "for year, gdp in zip(range(1995, 2023), gdp_per_capita_values):\n",
    "    df_master.loc[(df_master['Index Year'] == year) & (df_master['Country Name'] == 'North Korea'), ['GDP per capita (current USD)']] = gdp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, if a value is missing for any category, it's missing for all the years in that specific country.\n",
    "\n",
    "So we'll fill them with the average regional values. Ideally we'd seek other databases to get this information. But I don't have enough time budget for that.\n",
    "\n",
    "We'll only skip categorical values (which we'll process later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_interpolate_regional = [\n",
    "    'Inflation CPI', 'Labor force size', f'Trade (% of GDP)', f'Trade in services (% of GDP)',\n",
    "    'Under-5 mortality rate (per 1k live births)', 'Arable Land pct', 'Human Development Index',\n",
    "    'Migration Volume', 'Harmonized Test Scores']\n",
    "\n",
    "\n",
    "region_avg = df_master.groupby('Region')[to_interpolate_regional].transform('mean')\n",
    "\n",
    "df_master[to_interpolate_regional] = df_master[to_interpolate_regional].fillna(region_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4767 entries, 0 to 4766\n",
      "Data columns (total 48 columns):\n",
      " #   Column                                       Non-Null Count  Dtype  \n",
      "---  ------                                       --------------  -----  \n",
      " 0   Country Name                                 4767 non-null   object \n",
      " 1   Index Year                                   4767 non-null   int64  \n",
      " 2   Overall Score                                4767 non-null   float64\n",
      " 3   Property Rights                              4767 non-null   float64\n",
      " 4   Government Integrity                         4767 non-null   float64\n",
      " 5   Judicial Effectiveness                       4767 non-null   float64\n",
      " 6   Government Spending                          4767 non-null   float64\n",
      " 7   Tax Burden                                   4767 non-null   float64\n",
      " 8   Fiscal Health                                4767 non-null   float64\n",
      " 9   Business Freedom                             4767 non-null   float64\n",
      " 10  Monetary Freedom                             4767 non-null   float64\n",
      " 11  Labor Freedom                                4767 non-null   float64\n",
      " 12  Financial Freedom                            4767 non-null   float64\n",
      " 13  Investment Freedom                           4767 non-null   float64\n",
      " 14  Trade Freedom                                4767 non-null   float64\n",
      " 15  GDP per capita (current USD)                 4767 non-null   float64\n",
      " 16  Total population                             4767 non-null   float64\n",
      " 17  Gini                                         4767 non-null   float64\n",
      " 18  Inflation CPI                                4767 non-null   float64\n",
      " 19  Real interest rate                           4767 non-null   float64\n",
      " 20  Labor force size                             4767 non-null   float64\n",
      " 21  Trade (% of GDP)                             4767 non-null   float64\n",
      " 22  Trade in services (% of GDP)                 4767 non-null   float64\n",
      " 23  Under-5 mortality rate (per 1k live births)  4767 non-null   float64\n",
      " 24  Borders Length (in KM)                       4767 non-null   float64\n",
      " 25  Neighbouring Countries                       4767 non-null   object \n",
      " 26  isLandLocked                                 4767 non-null   bool   \n",
      " 27  n_accessToSea                                4767 non-null   int64  \n",
      " 28  Rail Density                                 4767 non-null   float64\n",
      " 29  Pctg of Rail Electrified                     4767 non-null   float64\n",
      " 30  Warred Against                               4490 non-null   object \n",
      " 31  Area Size (km2)                              4767 non-null   int64  \n",
      " 32  Expanded EconZone Area                       4767 non-null   int64  \n",
      " 33  Amount of Ports                              4767 non-null   int64  \n",
      " 34  Distance from Equator                        4767 non-null   float64\n",
      " 35  Majoritary Religions                         4767 non-null   object \n",
      " 36  Shape_Leng                                   4767 non-null   float64\n",
      " 37  Region                                       4767 non-null   object \n",
      " 38  Climate Type                                 4767 non-null   object \n",
      " 39  Average Temperature (C)                      4767 non-null   float64\n",
      " 40  Death rates from disasters                   4767 non-null   float64\n",
      " 41  H index (Academic Papers)                    4767 non-null   int64  \n",
      " 42  Arable Land pct                              4767 non-null   float64\n",
      " 43  Qualified Labor Force pct                    4767 non-null   float64\n",
      " 44  Human Development Index                      4767 non-null   float64\n",
      " 45  Natural Resources                            4767 non-null   float64\n",
      " 46  Migration Volume                             4767 non-null   float64\n",
      " 47  Harmonized Test Scores                       4767 non-null   float64\n",
      "dtypes: bool(1), float64(35), int64(6), object(6)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_master.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_countryNameAnalysis = df_master.groupby('Country Name').apply(lambda x: x.isna().mean())\n",
    "# df_countryNameAnalysis.to_csv('isna_groupedBy_CountryName.csv')\n",
    "\n",
    "# df_regionAnalysis = df_master.groupby('Region').apply(lambda x: x.isna().mean())\n",
    "# df_regionAnalysis.to_csv('isna_groupedBy_Region.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to convert some of our categorical features from Strings to Lists.\n",
    "\n",
    "def string_to_list(value):\n",
    "    try:\n",
    "        return ast.literal_eval(value)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "df_master['Neighbouring Countries'] = df_master['Neighbouring Countries'].apply(string_to_list)\n",
    "df_master['Warred Against'] = df_master['Warred Against'].apply(string_to_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master['Amount of Country Neighbours'] = df_master['Neighbouring Countries'].apply(lambda x: len(x))\n",
    "df_master['Amount of Major Conflicts_Since 1900'] = df_master['Warred Against'].apply(lambda x: len(x))\n",
    "\n",
    "df_master['Population Density'] = df_master['Total population'] / df_master['Area Size (km2)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming Shape_Leng to the same unit as borders length\n",
    "# To achieve that, we need to multiply Shape_Leng by 92.337581\n",
    "# Empirically found this out by looking at both columns for 'Czech Republic'\n",
    "df_master['Shape_Leng'] *= 92.337581\n",
    "\n",
    "df_master['Shared Borders (in pct)'] = df_master['Borders Length (in KM)'] / df_master['Shape_Leng']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Proportion of Rival Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_neighConflictAmnt = dict()\n",
    "\n",
    "def conflictsToPercentage(row, dict_master = dict_neighConflictAmnt):\n",
    "    '''\n",
    "        Given a series (which is a row in the DataFrame),\n",
    "        extract which countries are his neighbours, and how many of those he has fought with (in %)\n",
    "\n",
    "        Store the info in a dict. If extracted country already in dict, return dict values.\n",
    "    '''\n",
    "    # Extracting basic info\n",
    "    country = str(row['Country Name'])\n",
    "    neighbours = row['Neighbouring Countries']\n",
    "    if not isinstance(neighbours, list):\n",
    "        neighbours = []\n",
    "\n",
    "    opponents = row['Warred Against']\n",
    "    if not isinstance(opponents, list):\n",
    "        opponents = []        \n",
    "\n",
    "    # Early Returns\n",
    "    if not opponents or not neighbours:        \n",
    "        return {\n",
    "                #'Country Name': country,\n",
    "                #'Neighbouring Countries': neighbours,\n",
    "                #'Warred Against': opponents,\n",
    "                'Proportion of Rival Neighbours': 0\n",
    "            }\n",
    "    \n",
    "    if country in dict_master:        \n",
    "        return {\n",
    "            #'Country Name': country,\n",
    "            #'Neighbouring Countries': neighbours,\n",
    "            #'Warred Against': opponents,\n",
    "            'Proportion of Rival Neighbours': dict_master[country]\n",
    "        }\n",
    "    \n",
    "    # ------------------ Doing the actual calculation\n",
    "    neighbours = set(neighbours) # remove duplicates, if any\n",
    "    opponents = set(opponents) # remove duplicates\n",
    "    rivalCount = 0\n",
    "    totalNeighs = len(neighbours) \n",
    "    for neigh in neighbours:\n",
    "        if neigh in opponents:\n",
    "            rivalCount += 1\n",
    "\n",
    "    proportion = rivalCount/totalNeighs\n",
    "    dict_master[country] = proportion\n",
    "\n",
    "    return {\n",
    "        #'Country Name': country,\n",
    "        #'Neighbouring Countries': neighbours,\n",
    "        #'Warred Against': opponents,\n",
    "        'Proportion of Rival Neighbours': proportion\n",
    "    }\n",
    "    \n",
    "\n",
    "df_master['Proportion of Rival Neighbours'] = np.nan\n",
    "df_results = df_master.apply(conflictsToPercentage, axis=1, result_type='expand')\n",
    "df_master.update(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Mean Regional Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master['Regional Mean GDP per Capita'] = df_master.groupby(['Region', 'Index Year'])['GDP per capita (current USD)'].transform('mean')\n",
    "\n",
    "df_master['Regional Mean GDP'] = \\\n",
    "    df_master.groupby(['Region', 'Index Year'])['GDP per capita (current USD)'].transform('mean') \\\n",
    "    * df_master.groupby(['Region', 'Index Year'])['Total population'].transform('mean')\n",
    "\n",
    "df_master['Regional Mean Gini'] = df_master.groupby(['Region', 'Index Year'])['Gini'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neigh_meanStats(row, df=df_master):\n",
    "    '''\n",
    "        Returns calculated columns for:\n",
    "            • Mean GDP of neighboring + regional countries\n",
    "            • Mean GDP per Capita of neighboring + regional countries\n",
    "            • Mean Neighboring + regional Countries Gini coefficient\n",
    "    '''\n",
    "    \n",
    "    country = str(row['Country Name'])\n",
    "    year = row['Index Year']\n",
    "    neighbours = row['Neighbouring Countries']\n",
    "\n",
    "    regional_GDP_perCapita = row['Regional Mean GDP per Capita']\n",
    "    regional_GDP = row['Regional Mean GDP']\n",
    "    regional_Gini = row['Regional Mean Gini']\n",
    "\n",
    "\n",
    "    if not isinstance(neighbours, list):\n",
    "        neighbours = []\n",
    "    \n",
    "    # If there are no neighbours, we don't even need to calculate anything\n",
    "    if not neighbours:\n",
    "        #display(f'No neighbours found for {country}')\n",
    "        return {\n",
    "            'Local Mean GDP per Capita': regional_GDP_perCapita,\n",
    "            'Local Mean GDP': regional_GDP,\n",
    "            'Local Mean Gini': regional_Gini\n",
    "    }\n",
    "    \n",
    "    # ------------------------------- Actual calculation\n",
    "    # We'll do a mean of Regional and Neighbourhood Data. But first, we need to create Neighbourhood Data\n",
    "\n",
    "    neighCount = 0\n",
    "    GDP_count = 0\n",
    "    GDPperCapita_count = 0\n",
    "    Gini_count = 0\n",
    "\n",
    "    for neigh in neighbours:\n",
    "        neigh_data_GDP = df.loc[(df['Index Year'] == year) & (df['Country Name'] == neigh), 'GDP per capita (current USD)']\n",
    "        neigh_data_population = df.loc[(df['Index Year'] == year) & (df['Country Name'] == neigh), 'Total population']\n",
    "        neigh_data_Gini = df.loc[(df['Index Year'] == year) & (df['Country Name'] == neigh), 'Gini']\n",
    "\n",
    "        if not neigh_data_GDP.empty and not neigh_data_population.empty:\n",
    "            GDP_count += neigh_data_GDP.iloc[0] * neigh_data_population.iloc[0]\n",
    "            neighCount += 1\n",
    "        #else:\n",
    "            #display(f'{country} is having problems on neigh_data_GDP or neigh_data_population. Neigh: {neigh}')\n",
    "\n",
    "        if not neigh_data_GDP.empty:\n",
    "            GDPperCapita_count += neigh_data_GDP.iloc[0]\n",
    "        #else:\n",
    "            #display(f'{country} is having problems on neigh_data_GDP (only the second time). Neigh: {neigh}')\n",
    "\n",
    "        if not neigh_data_Gini.empty:\n",
    "            Gini_count += neigh_data_Gini.iloc[0]\n",
    "        #else:\n",
    "            #display(f'{country} is having problems on Gini_count. Neigh: {neigh}')\n",
    "\n",
    "\n",
    "    return {\n",
    "        'Local Mean GDP per Capita': ((GDPperCapita_count/neighCount) + regional_GDP_perCapita)/2,\n",
    "        'Local Mean GDP': ((GDP_count/neighCount) + regional_GDP)/2,\n",
    "        'Local Mean Gini': ((Gini_count/neighCount) + regional_Gini)/2\n",
    "    }\n",
    "    \n",
    "df_master['Local Mean GDP per Capita'] = np.nan\n",
    "df_master['Local Mean GDP'] = np.nan\n",
    "df_master['Local Mean Gini'] = np.nan\n",
    "df_results = df_master.apply(neigh_meanStats, axis=1, result_type='expand')\n",
    "#df_results = df_master.loc[(df_master['Country Name'] == 'Germany')].apply(neigh_meanStats, axis=1, result_type='expand')\n",
    "df_master.update(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encoding some categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the string-list representation into a comma-separated string\n",
    "df_master['Majoritary Religions'] = df_master['Majoritary Religions'].apply(lambda x: ','.join(ast.literal_eval(x)))\n",
    "\n",
    "# One-hot encode the 'Majoritary Religions' using str.get_dummies()\n",
    "one_hot_encoding_religions = df_master['Majoritary Religions'].str.get_dummies(sep=',').add_prefix('Religion_')\n",
    "\n",
    "# Concatenate the one-hot encoded dataframe with the original dataframe\n",
    "df_master = pd.concat([df_master, one_hot_encoding_religions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_climate = pd.get_dummies(df_master['Climate Type'], prefix='ClimateType')\n",
    "\n",
    "# Concatenate the one-hot encoded dataframe with the original dataframe\n",
    "df_master = pd.concat([df_master, one_hot_encoded_climate], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting unusable columns\n",
    "We don't have a use for some of the columns anymore, so..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.drop(columns=['Overall Score','Borders Length (in KM)','Neighbouring Countries','Warred Against','Majoritary Religions','Shape_Leng','Region','Regional Mean GDP per Capita','Regional Mean GDP','Regional Mean Gini'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.to_csv('..\\\\Data_Sets\\\\processed\\\\completeData_1995-2022.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EconStats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
