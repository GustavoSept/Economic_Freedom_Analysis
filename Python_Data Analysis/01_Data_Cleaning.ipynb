{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff5b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 350)\n",
    "pd.set_option('display.min_rows', 135)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f928fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging\n",
    "#logging.basicConfig(level=logging.DEBUG)  # Change the level to control verbosity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef69d9b8",
   "metadata": {},
   "source": [
    "# Set the structure for relative paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dcee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "relativePath_EF = \"..\\Data_Sets\\originalData\\EconomicFreedom_Heritage_1995-2023.csv\"\n",
    "relativePath_devInd = \"..\\Data_Sets\\originalData\\WorldDevelopmentIndicators_1960-2022.csv\"\n",
    "\n",
    "df_EF = pd.read_csv(relativePath_EF) #Economic Freedom Data Set from Heritage\n",
    "df_WB = pd.read_csv(relativePath_devInd) #Some Development Indicators from World Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bead4f",
   "metadata": {},
   "source": [
    "# Fixing Country Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ef3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing column names to match each other\n",
    "df_EF.rename(columns={\"Name\": \"Country Name\"}, inplace=True)\n",
    "df_WB.rename(columns={\"Time\": \"Index Year\"}, inplace=True)\n",
    "\n",
    "#------------------ Cleaning extra-space in the end of strings, and making country names consistent\n",
    "#(PS: ISO Code and Country Code uses different standards)\n",
    "\n",
    "#removing extra spaces\n",
    "df_EF[\"Country Name\"] = df_EF[\"Country Name\"].str.strip()\n",
    "\n",
    "#Renaming Countries from df_EF to df_WB standard\n",
    "df_EF.loc[df_EF[\"Country Name\"] == \"Côte d'Ivoire\", \"Country Name\"] = \"Cote d'Ivoire\"\n",
    "df_EF.loc[df_EF[\"Country Name\"] == \"São Tomé and Príncipe\", \"Country Name\"] = \"Sao Tome and Principe\"\n",
    "df_EF.loc[df_EF[\"Country Name\"] == \"The Philippines\", \"Country Name\"] = \"Philippines\"\n",
    "df_EF.loc[df_EF[\"Country Name\"] == \"Burma\", \"Country Name\"] = \"Myanmar\"\n",
    "df_EF.loc[df_EF[\"Country Name\"] == \"Cabo Verde\", \"Country Name\"] = \"Cape Verde\"\n",
    "\n",
    "#Fixing double standard naming in df_EF\n",
    "df_EF.loc[df_EF[\"Country Name\"] == \"Macedonia\", \"Country Name\"] = \"North Macedonia\"\n",
    "df_EF.loc[df_EF[\"Country Name\"] == \"Slovakia\", \"Country Name\"] = \"Slovak Republic\"\n",
    "df_EF.loc[df_EF[\"Country Name\"] == \"Swaziland\", \"Country Name\"] = \"Eswatini\"\n",
    "df_EF.loc[df_EF[\"Country Name\"] == \"The Netherlands\", \"Country Name\"] = \"Netherlands\"\n",
    "\n",
    "#Renaming Countries from df_WB to df_EF standard\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Czechia\", \"Country Name\"] = \"Czech Republic\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Cabo Verde\", \"Country Name\"] = \"Cape Verde\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Congo, Dem. Rep.\", \"Country Name\"] = \"Democratic Republic of Congo\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Congo, Rep.\", \"Country Name\"] = \"Republic of Congo\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Egypt, Arab Rep.\", \"Country Name\"] = \"Egypt\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Hong Kong SAR, China\", \"Country Name\"] = \"Hong Kong\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Iran, Islamic Rep.\", \"Country Name\"] = \"Iran\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Lao PDR\", \"Country Name\"] = \"Laos\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Macao SAR, China\", \"Country Name\"] = \"Macau\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Micronesia, Fed. Sts.\", \"Country Name\"] = \"Micronesia\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Korea, Dem. People's Rep.\", \"Country Name\"] = \"North Korea\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Korea, Rep.\", \"Country Name\"] = \"South Korea\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Russian Federation\", \"Country Name\"] = \"Russia\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"St. Lucia\", \"Country Name\"] = \"Saint Lucia\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"St. Vincent and the Grenadines\", \"Country Name\"] = \"Saint Vincent and the Grenadines\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Syrian Arab Republic\", \"Country Name\"] = \"Syria\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Bahamas, The\", \"Country Name\"] = \"The Bahamas\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Gambia, The\", \"Country Name\"] = \"The Gambia\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Turkiye\", \"Country Name\"] = \"Turkey\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Venezuela, RB\", \"Country Name\"] = \"Venezuela\"\n",
    "df_WB.loc[df_WB[\"Country Name\"] == \"Yemen, Rep.\", \"Country Name\"] = \"Yemen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa2f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- Removing some unnecessary rows and columns\n",
    "EF_dropCases = [\"Short Name\",\"ISO Code\", \"Id\"]\n",
    "df_EF = df_EF.drop(EF_dropCases,axis=1) #axis 1 drops along the column axis\n",
    "\n",
    "WB_dropCases = [\"Country Code\",\"Time Code\"]\n",
    "df_WB = df_WB.drop(WB_dropCases,axis=1) #axis 1 drops along the column axis\n",
    "\n",
    "#drops those pesky lines at the end of df_WB\n",
    "df_WB = df_WB.drop(df_WB.tail(4).index) \n",
    "\n",
    "#------------------ Removing Countries from df_WB that don't appear on df_EF\n",
    "\n",
    "df_eligibleCountries = df_EF[\"Country Name\"].unique()\n",
    "filtered_df_WB = df_WB[df_WB['Country Name'].isin(df_eligibleCountries)]\n",
    "\n",
    "#print(\"df_EF\", df_EF[\"Country Name\"].nunique())\n",
    "#print(\"df_WB\", df_WB['Country Name'].nunique())\n",
    "#print(\"filtered_df_WB\", filtered_df_WB[\"Country Name\"].nunique())\n",
    "\n",
    "missing_countries = df_EF[~df_EF[\"Country Name\"].isin(filtered_df_WB[\"Country Name\"])] # the ~ is a negation operator\n",
    "print(\"missing_countries\", missing_countries['Country Name'].unique())\n",
    "#For now, I'll let Taiwan be missing.\n",
    "\n",
    "\n",
    "df_master = pd.merge(filtered_df_WB, df_EF, on=[\"Country Name\", \"Index Year\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c522728",
   "metadata": {},
   "source": [
    "# Organizing and Sorting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4df6cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-ordering and sorting some columns\n",
    "\n",
    "#Renaming some columns\n",
    "df_master = df_master.rename(columns={\n",
    "    'GDP per capita (constant 2015 US$) [NY.GDP.PCAP.KD]': 'GDP per capita (const 2015USD)',\n",
    "    'GDP per capita (current US$) [NY.GDP.PCAP.CD]': 'GDP per capita (current USD)',\n",
    "    'GDP per capita growth (annual %) [NY.GDP.PCAP.KD.ZG]': 'GDP per capita growth',\n",
    "    'GDP per capita, PPP (constant 2017 international $) [NY.GDP.PCAP.PP.KD]': 'GDP PPP per capita (const 2017USD)',\n",
    "    'Gini index [SI.POV.GINI]': 'Gini',\n",
    "    'Inflation, consumer prices (annual %) [FP.CPI.TOTL.ZG]': 'Inflation CPI',\n",
    "    'Labor force participation rate, total (% of total population ages 15-64) (modeled ILO estimate) [SL.TLF.ACTI.ZS]': 'Labor force size',\n",
    "    'Land area (sq. km) [AG.LND.TOTL.K2]': 'Land area (sq. km)',\n",
    "    'Life expectancy at birth, total (years) [SP.DYN.LE00.IN]': 'Life expectancy at birth',\n",
    "    'Mortality rate, under-5 (per 1,000 live births) [SH.DYN.MORT]': 'Under-5 mortality rate (per 1k live births)',\n",
    "    'Population living in slums (% of urban population) [EN.POP.SLUM.UR.ZS]': 'Population living in slums (as % of urban)',\n",
    "    'Population, total [SP.POP.TOTL]': 'Total population',\n",
    "    'Poverty gap at $2.15 a day (2017 PPP) (%) [SI.POV.GAPS]': 'Poverty gap at $2.15 a day (% of population)',\n",
    "    'Poverty gap at $6.85 a day (2017 PPP) (%) [SI.POV.UMIC.GP]': 'Poverty gap at $6.85 a day (% of population)',\n",
    "    'Real interest rate (%) [FR.INR.RINR]': 'Real interest rate',\n",
    "    'Trade (% of GDP) [NE.TRD.GNFS.ZS]': 'Trade (% of GDP)',\n",
    "    'Trade in services (% of GDP) [BG.GSR.NFSV.GD.ZS]': 'Trade in services (% of GDP)'\n",
    "})\n",
    "\n",
    "# Define the desired column order\n",
    "columnList = [\n",
    "    'Country Name',\n",
    "    'Index Year',\n",
    "    'Overall Score',\n",
    "    'Property Rights',\n",
    "    'Government Integrity',\n",
    "    'Judicial Effectiveness',\n",
    "    'Government Spending',\n",
    "    'Tax Burden',\n",
    "    'Fiscal Health',\n",
    "    'Business Freedom',\n",
    "    'Monetary Freedom',\n",
    "    'Labor Freedom',\n",
    "    'Financial Freedom',\n",
    "    'Investment Freedom',\n",
    "    'Trade Freedom',\n",
    "    'GDP per capita (const 2015USD)',\n",
    "    'GDP per capita (current USD)',\n",
    "    'GDP per capita growth',\n",
    "    'GDP PPP per capita (const 2017USD)',\n",
    "    'Total population',\n",
    "    'Land area (sq. km)',\n",
    "    'Gini',\n",
    "    'Inflation CPI',\n",
    "    'Real interest rate',\n",
    "    'Labor force size',\n",
    "    'Trade (% of GDP)',\n",
    "    'Trade in services (% of GDP)',\n",
    "    'Poverty gap at $2.15 a day (% of population)',\n",
    "    'Poverty gap at $6.85 a day (% of population)',\n",
    "    'Population living in slums (as % of urban)',\n",
    "    'Life expectancy at birth',\n",
    "    'Under-5 mortality rate (per 1k live births)']\n",
    "\n",
    "#Creating the Master Data Frame, and purging older DFs/variables from memory \n",
    "df_master = pd.DataFrame(df_master, columns=columnList)\n",
    "\n",
    "del missing_countries, filtered_df_WB, \\\n",
    "    df_eligibleCountries, df_EF, df_WB\n",
    "\n",
    "#---------------- sorting the DataFrame\n",
    "df_master = df_master.sort_values(by=[\"Country Name\", \"Index Year\"], ascending=[True, True])\n",
    "\n",
    "#resetting indexing\n",
    "df_master = df_master.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e13081d",
   "metadata": {},
   "source": [
    "# Filling and Converting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceedfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace problematic values with NaN\n",
    "df_master.replace(['', '..'], np.nan, inplace=True)\n",
    "\n",
    "#Fixing some Data Types\n",
    "toFloatColumns = df_master.iloc[:,2:].columns #selecting all columns, except Country Name and Index Year\n",
    "df_master[toFloatColumns] = df_master[toFloatColumns].astype(float)\n",
    "\n",
    "df_master['Index Year'] = df_master['Index Year'].astype(int)\n",
    "#df_master['Total population'] = df_master['Total population'].astype(int)\n",
    "df_master['Total population'] = pd.to_numeric(df_master['Total population'], errors='coerce')\n",
    "\n",
    "\n",
    "#rounding numbers up to the 4th decimal place, so it's easier to read\n",
    "df_master[toFloatColumns] = df_master[toFloatColumns].round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7dd1aa",
   "metadata": {},
   "source": [
    "_Note: This approach for interpolation is moderately slow. But since our dataset isn't that big, it's not a problem._\n",
    "\n",
    "**I don't advise it on really large datasets though**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8639827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolateMiddle(series, timeField_series, n_times=0, extrapolate=4):\n",
    "    '''\n",
    "    Essentially, just fill the middle values (n_times) for any given Series, and project past/future for (extrapolate) times.\n",
    "    \n",
    "    series: the series to interpolate\n",
    "    timeField_series: corresponding time data for the series\n",
    "    n_times: interpolation reach. If zero, find maximum value based on 'field'.\n",
    "    extrapolate: how much time to project past \"middle data\"\n",
    "    '''\n",
    "    \n",
    "    # If invalid, we'll pick a value that works in this DataSet.\n",
    "    if n_times <= 0:\n",
    "        n_times = int((2022-1960)/2)\n",
    "    \n",
    "    # Setting points to help determine 'middle' data\n",
    "    earliest_time = timeField_series.loc[series.notna()].min()\n",
    "    latest_time = timeField_series.loc[series.notna()].max()\n",
    "    \n",
    "    # If there's no non-NaN value, return the Series as-is\n",
    "    if pd.isna(earliest_time) or pd.isna(latest_time):\n",
    "        return series\n",
    "    \n",
    "    # Only interpolate what has been defined as \"middle data\"\n",
    "    maskedtimes = (timeField_series >= earliest_time)&(timeField_series <= latest_time)    \n",
    "    temp_series = series[maskedtimes]\n",
    "    temp_series.interpolate(method='linear', limit=n_times, limit_direction='both', inplace=True)    \n",
    "    \n",
    "    # Update the original Series with interpolated middle data\n",
    "    series[maskedtimes] = temp_series\n",
    "    \n",
    "    if extrapolate > 0:\n",
    "        temp_series = series\n",
    "        temp_series.interpolate(method='linear', limit=extrapolate, limit_direction='both', inplace=True)\n",
    "    \n",
    "        # Update the original Series (on extrapolate step)\n",
    "        series = temp_series\n",
    "    \n",
    "    return series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7544815",
   "metadata": {},
   "source": [
    "We'll interpolate each column separately, so that we can control exactly how much we'll extrapolate. Also, we won't fill every possible row (as this data wouldn't be reliable at all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba05d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating how much data we're missing before interpolation, from 1995 onward\n",
    "missingData1 = (df_master[df_master[\"Index Year\"] >= 1995].isna().mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7b87e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_interpolate = list(df_master.columns)\n",
    "socioEconList = to_interpolate[15:]\n",
    "econFreedomList = to_interpolate[2:15]\n",
    "\n",
    "def process_group(group, column, *args, **kwargs):\n",
    "    timeField_series = group['Index Year']\n",
    "    group[column] = interpolateMiddle(group[column], timeField_series, *args, **kwargs)\n",
    "    return group\n",
    "\n",
    "# Process each column in econFreedomList\n",
    "for col in econFreedomList:\n",
    "    print(col)\n",
    "    df_master = df_master.groupby(by=['Country Name']).apply(lambda group: process_group(group, col, n_times=4, extrapolate=1)).reset_index(drop=True)\n",
    "\n",
    "# Process each column in socioEconList\n",
    "for col in socioEconList:\n",
    "    print(col)\n",
    "    df_master = df_master.groupby(by=['Country Name']).apply(lambda group: process_group(group, col, n_times=7, extrapolate=4)).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0bbb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingData2 = (df_master[df_master[\"Index Year\"] >= 1995].isna().mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b865087",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Difference in Missing Data, before and after Custom Interpolation\")\n",
    "missingData2 - missingData1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ee7661",
   "metadata": {},
   "source": [
    "These are one of the most problematic countries, in terms of Gini data.\n",
    "\n",
    "I can't go too far with interpolation, because some countries would simply be a straight line in some features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3827147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of countries to plot\n",
    "countries_to_plot = ['Venezuela', 'Trinidad and Tobago', 'The Bahamas', 'Syria', 'Singapore', 'Republic of Congo', 'Myanmar', 'Lesotho', 'Democratic Republic of Congo', 'Gabon']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Loop through each country and plot\n",
    "for country in countries_to_plot:\n",
    "    df_filtered = df_master[df_master['Country Name'] == country][['Index Year', 'Gini']]\n",
    "    df_filtered = df_filtered.sort_values(by='Index Year')\n",
    "    plt.plot(df_filtered['Index Year'], df_filtered['Gini'], marker='o', label=country)\n",
    "\n",
    "plt.title('Gini Coefficient Over the Years')\n",
    "plt.xlabel('Index Year')\n",
    "plt.ylabel('Gini Coefficient')\n",
    "plt.ylim(25, 65)  # Limit y-axis from 20 to 55\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee5d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing some Data Types\n",
    "\n",
    "df_master['Index Year'] = df_master['Index Year'].astype(int)\n",
    "df_master['Total population'] = pd.to_numeric(df_master['Total population'], errors='coerce')\n",
    "\n",
    "toFloatColumns = df_master.iloc[:,2:].columns #selecting all columns, except Country Name and Index Year\n",
    "df_master[toFloatColumns] = df_master[toFloatColumns].astype(float)\n",
    "\n",
    "#rounding numbers up to the 4th decimal place, so it's easier to read\n",
    "df_master[toFloatColumns] = df_master[toFloatColumns].round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2ff90a",
   "metadata": {},
   "source": [
    "# Binning Countries into Quintiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128eb304",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['Q1','Q2','Q3','Q4','Q5']\n",
    "\n",
    "# Function to apply for each year\n",
    "def calculate_quintiles(df_year):\n",
    "    if len(df_year) > 0 and df_year['GDP per capita (current USD)'].notna().any():  \n",
    "        df_year['Country Quintile'] = pd.qcut(df_year['GDP per capita (current USD)'].dropna(), \n",
    "                                              q=5, \n",
    "                                              labels=group_names, \n",
    "                                              duplicates='drop')\n",
    "    return df_year\n",
    "\n",
    "# Group by 'Index Year' and apply the function\n",
    "df_master = df_master.groupby('Index Year', as_index=False).apply(calculate_quintiles)\n",
    "df_master.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Fill missing Quintiles with Q1 (From 1995 onward, because they're all poor anyway)\n",
    "df_master.loc[df_master[\"Index Year\"] >= 1995, 'Country Quintile']\\\n",
    "    = df_master.loc[df_master[\"Index Year\"] >= 1995, 'Country Quintile'].fillna('Q1')\n",
    "\n",
    "# Transforming data type to categorical\n",
    "df_master['Country Quintile'] = df_master['Country Quintile'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5203b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Full Data with no drops\n",
    "df_master.to_csv('..\\Data_Sets\\processed\\economicData_1960-2022_noNaN-drops.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6018914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning EconFreedom Parameters\n",
    "# We'll drop more values on other notebooks, as needed. I want to keep as much useful data as possible for the EDA stage.\n",
    "df_master.dropna(thresh=8,\n",
    "                 axis=0,\n",
    "                 inplace = True,\n",
    "                 subset =[\n",
    "                 'Overall Score',\n",
    "                 'Property Rights',\n",
    "                 'Government Integrity',\n",
    "                 'Judicial Effectiveness',\n",
    "                 'Government Spending',\n",
    "                 'Tax Burden',\n",
    "                 'Fiscal Health',\n",
    "                 'Business Freedom',\n",
    "                 'Monetary Freedom',\n",
    "                 'Labor Freedom',\n",
    "                 'Financial Freedom',\n",
    "                 'Investment Freedom',\n",
    "                 'Trade Freedom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f58d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "econFreedom = df_master[(df_master['Index Year'] <= 2022) & (df_master['Index Year'] >= 1995)]\n",
    "econFreedom.to_csv('..\\Data_Sets\\processed\\economicData_1995-2022.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38830f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
